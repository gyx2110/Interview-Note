# **专业基础**

## **进程和线程的区别**

 

进程是程序的运行实例，是向操作系统申请资源的基本单位。

线程是进程中可独立运行的最小单位，一个进程可以包含多个线程。

每个进程有自己独立的内存空间，文件句柄，数据集。

这些资源会被线程共享，同时在这基础上线程拥有独立的栈空间、局部变量表、程序计数器

 

 

 

 

 

 

## **TCP和UDP的区别**

TCP面向连接，传输数据之前要需要建立会话。UDP是无连接的。

TCP提供可靠传输，保证数据不丢包、不重复且按顺序到达；UDP只尽努力交付，不保证可靠交付

TCP提供了流量控制来协调双方传输数据的速度；UDP不提供

TCP只支持点到点通信；UDP支持一对一、一对多、多对多的交互通信。

TCP首部开销大20字节，UDP首部开销小8字节。

## **TCP实现可靠传输的机制**

序列号、确认应答、重传机制(超时定时器)

**流量控制(窗口大小)、**

![img](assets/wpsTegHTM.jpg) 

当窗口值为0，而接受方把窗口值恢复（比如ACK=1，ack=601，rwnd=200），但确认丢失，进入相互等待的死锁局面。所以如果窗口值为0，**发送端就会开启一个持续计数器，每个一段时间询问一下接收方。**

 

 

 

 

 

 

**拥塞控制**

swnd=min（rwnd，cwnd），cwnd就是拥塞窗口大小。

慢开始和拥塞避免

![img](assets/wpsRmVXLY.png) 

ssthresh：处理拥塞时参照的一个参数。例子中初始值为16，后来变为12。

当cwnd> ssthresh，cwnd以慢开始的方法指数增长；

当cwnd< ssthresh，cwnd以拥塞避免的方法线性增长。

值得注意的几个点

1上图是cwnd随传输轮次的变化，每过一个RTT就算一轮。

2超时就可以认为是拥塞了

快重传和快恢复：上一个算法的加强版

![img](assets/wpsnPFpvk.png) 

快重传：收到3个同样的确认就立刻重传，不等到超时；

快恢复：cwnd不是从1重新开始。

## **GET和POST的区别**

 

GET和POST都是TCP数据包，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同，

get请求通过url传递参数所以会受到长度限制，post没有这个限制。

get请求可以被浏览器缓存，post不可以。 

GET请求是幂等的，多次请求的结果是一样，而POST不幂等。

## **HTTP的报文格式**

![img](assets/wpsnrHfn5.jpg)![img](file:////var/folders/nl/bnrfmw912019ds4sjvsv3lp40000gn/T/com.kingsoft.wpsoffice.mac/wps-admin/ksohtml/wpsXjv9gs.jpg) 

## **HTTP方法**

GET	获取资源	1.0、1.1

POST	传输实体主体	1.0、1.1

PUT	传输文件	1.0、1.1

HEAD	获得报文首部	1.0、1.1

DELETE	删除文件	1.0、1.1

OPTIONS	询问支持的方法	1.1

# **Java**

 

## **String、StringBuffer、StringBuilder**

**String为什么是final**

主要是为了”安全性“和”效率“的缘故，因为：

1、避免了因为继承引起的安全隐患，由于String类被final修饰，所以就不会没修改；

2、有助于共享，提高性能，String类在程序中是用的比较多的，可以将字符串对象保存在字符串常量池中以供与字面值相同字符串对象共享。

3、这样在多线程时，对String对象的访问是可以保证安全的。String被设计为不变类，其中的value[]都被设计成private final的。

**三者区别**

![img](assets/wpsQXiN8Z.png) 

**StringBuilder**

![img](assets/wpsKiRn8k.png) 

![img](assets/wpszMF0uC.png) 

![img](assets/wpsRvywgX.png) 

**StringBuffer**

![img](assets/wpsheq58t.png) 

通过底层代码我们可以看到StringBuilder 与StringBuffer在拼接字符串时，通过判断字符串长度是否足够，从而创建一个新的数组用来封装数据，而原来的对象被放弃引用，等待垃圾回收，从而减少内存的浪费，因此在拼接字符串等操作时，我们通常使用StringBuilder 与StringBuffer，但两者在执行效率上又有不同，因为StringBuffer是线程安全的。 

StringBuffer、StringBuilder的方法都会调用AbstractStringBuilder中的公共方法，如上面的两段源码中都调用了super.append(str); 只是StringBuffer会在方法上加synchronized关键字，进行同步。

**String**

String类中使用字符数组保存字符串，如下就是，因为有“final”修饰符，所以可以知道string对象是不可变的。在每次对string类型进行改变的时候其实都等同与生成了一个新的String对象.然后引用指向这个新的String对象

总结:

String：适用于少量的字符串操作的情况

StringBuilder：适用于单线程下在字符缓冲区进行大量操作的情况

StringBuffer：适用多线程下在字符缓冲区进行大量操作的情况

 

## **HashMap**

**序言**

HashMap

底层使用数组加链表存储数据 .采用链地址法解决冲突，1.8之后引入了红黑树来优化hash冲突较多导致链表过长的现象。不是线程安全的，所以在多线程情况下会有线程安全的问题。它的容量始终是会保持在2的n次方，这个容量在计算hash值和扩容的时候，是有好处的。

**核心方法**

**hash**

static final int hash(Object key) {

​    int h;

​    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);

}

HashMap的散列方法如上，其实就是将hash值的高16位和低16位异或，我们将马上看到hash在与n - 1相与的时候，高位的信息也被考虑了，能使碰撞的概率减小，散列得更均匀。

 

关键就是这句`(n - 1) & hash`，这行代码是把待插入的结点散列到数组中某个下标中， n是table的容量即`table.length`，2的次幂用二进制表示的话，只有最高位为1，其余为都是0。减去1，刚好就反了过来。可以**使得散列值分布得更均匀**，且当n为2的次幂时候有`(n - 1) & hash == hash % n`, **使用位运算效率更高。**

 

**put**

put方法主要由putVal方法实现：

1.如果没有产生hash冲突，直接在数组tab[i = (n - 1) & hash]处新建一个结点；

2.否则，发生了hash冲突，此时key如果和头结点的key相同，不进行查找过程，直接跳到最后去更新值

3.否则，如果数组下标中的类型是TreeNode，就插入到红黑树中

4.如果上面的条件都不满足，那就是只是普通的链表，就在链表中查找或替换，找到key相同的结点就跳出，到最后去更新值；如果说到链表尾也没有找到key相同的结点就在尾部插入一个新结点。接着判断此时链表长度若大于8的话，还需要将链表转为红黑树。

5.最后会检查元素大小是否超过阀值，来决定要不要进行一个扩容。

final V putVal(int hash, K key, V value, boolean onlyIfAbsent,

​                   boolean evict) {

​        Node<K,V>[] tab; Node<K,V> p; int n, i;

​        if ((tab = table) == null || (n = tab.length) == 0)

​            n = (tab = resize()).length;

​        if ((p = tab[i = (n - 1) & hash]) == null)

​            tab[i] = newNode(hash, key, value, null);

​        else {

​            Node<K,V> e; K k;

​            if (p.hash == hash &&

​                ((k = p.key) == key || (key != null && key.equals(k))))

​                e = p;

​            else if (p instanceof TreeNode)

​                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);

​            else {

​                for (int binCount = 0; ; ++binCount) {

​                    if ((e = p.next) == null) {

​                        p.next = newNode(hash, key, value, null);

​                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st

​                            treeifyBin(tab, hash);

​                        break;

​                    }

​                    if (e.hash == hash &&

​                        ((k = e.key) == key || (key != null && key.equals(k))))

​                        break;

​                    p = e;

​                }

​            }

​            if (e != null) { // existing mapping for key

​                V oldValue = e.value;

​                if (!onlyIfAbsent || oldValue == null)

​                    e.value = value;

​                afterNodeAccess(e);

​                return oldValue;

​            }

​        }

​        ++modCount;

​        if (++size > threshold)

​            resize();

​        afterNodeInsertion(evict);

​        return null;

​    }

**resize**

扩容在1.8中是有初始功能的

![img](assets/wpssuUcnq.png) 

**指定容量使用指定容量，没有指定使用默认容量。**

**已有哈希表扩容时，容量、阈值均翻倍**

if (oldTab != null) {

​            for (int j = 0; j < oldCap; ++j) {

​                Node<K,V> e;

​                if ((e = oldTab[j]) != null) {

​                    oldTab[j] = null;

​                    // 如果数组中只有一个元素，即只有一个头结点，重新哈希到新数组的某个下标

​                    if (e.next == null)

​                        newTab[e.hash & (newCap - 1)] = e;

​                    else if (e instanceof TreeNode)

​                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);

​                    else { // preserve order

​                        // 数组下标处的链表长度大于1，非红黑树的情况

​                        Node<K,V> loHead = null, loTail = null;

​                        Node<K,V> hiHead = null, hiTail = null;

​                        Node<K,V> next;

​                        do {

​                            next = e.next;

​                            // oldCap是2的次幂，最高位是1，其余为是0，哈希值和其相与，根据哈希值的最高位是1还是0，链表被拆分成两条，哈希值最高位是0分到loHead。

​                            if ((e.hash & oldCap) == 0) {

​                                if (loTail == null)

​                                    loHead = e;

​                                else

​                                    loTail.next = e;

​                                loTail = e;

​                            }

​                            // 哈希值最高位是1分到hiHead

​                            else {

​                                if (hiTail == null)

​                                    hiHead = e;

​                                else

​                                    hiTail.next = e;

​                                hiTail = e;

​                            }

​                        } while ((e = next) != null);

​                        if (loTail != null) {

​                            loTail.next = null;

​                            // loHead挂到新数组[原下标]处；

​                            newTab[j] = loHead;

​                        }

​                        if (hiTail != null) {

​                            hiTail.next = null;

​                            // hiHead挂到新数组中[原下标+oldCap]处

​                            newTab[j + oldCap] = hiHead;

​                        }

​                    }

​                }

​            }

​        }

​        return newTab;

举个例子，比如oldCap是16，二进制表示是10000，hash值的后五位和oldCap相与，因为oldCap的最高位（从右往左数的第5位）是1其余位是0，因此hash值的该位是0的所有元素被分到一条链表，挂到新数组中原下标处，hash值该位为1的被分到另外一条链表，挂到新数组中原下标+oldCap处。举个例子：桶0中的元素其hash值后五位是0XXXX的就被分到桶0种，其hash值后五位是1XXXX就被分到桶4中。(组之间保持原来的顺序，这样计算很巧妙阿，不用对每个元素计算hash了)

 

扩容过程中几个关键的点：

新初始化哈希表时，容量为默认容量，阈值为 容量*加载因子

如果之前这个桶的节点类型是树，需要把新哈希表里当前桶也变成树形结构

 

**线程不安全表现**

主要表现在resize()时会产生环形链表(1.7中)

因为采用的是头插法，如果一个线程**执行扩容的时候被时间片用完，而另一个线程完成了扩容过程**，则**这时对线程一来说，链表就产生逆序**了，会让后面的结点指向前面的结点，从而形成环。

1.7中put可能会导致数据丢失，扩容时会产生两个表，put进的数据还是放在旧表中，这样如何放到了已经扫过的链，就不会进行迁移。

put时只会保留最后执行的结果，造成数据不一致

(1.7中的put用的是头插，1.8用的是尾插，包括在rehash中)

## **HashMap和HashTable的区别**

1.map线程不安全，table通过syn保证线程安全

2.map的key和value允许为null，table则不允许

3. 初始容量和扩容时的大小不同，map是16，扩容容量翻倍且保持在2^n，table是11,扩容每次容量2*n+1

4.计算hash方法不同，map：hashcode高16位和低十六位进行异或  table是直接用hashcode

 

 

 

 

 

 

 

## **ArrayList和LinkedList的区别**

1.ArrayList是实现了基于动态数组的数据结构，LinkedList基于双向链表的数据结构。 所以arraylist是有界的，这个界是Integer的最大值。LinkedList在设计上没有容量的限制。

2.ArrayList支持随机访问，而LinkedList必须要通过指针来遍历。 

3.对于插入和删除操作ArrayList要通过System.arraycopy方法移动数据，虽然它是一个用C实现的native方法。 但是需要把数组的一部分元素给挪动一遍，这个开销在数据比较多的时候是比较大的。LinedList比较占优势，因为只要改变几个指针的值就可以了。

4.LinkedLit实现了Deque接口，所以可以当做栈和队列使用。

## **ConcurrentHashMap**

序言

ConcurrentHashMap出现的背景是线程不安全的HashMap、效率低下的HashTable容器

它底层是一个Segment数组，Segment继承自ReentrantLock，所以它本身就是一把锁。

这种分段锁机制可以很好的提升并发性，因为它使得段与段之间的访问是各自独立的。

定位段的两个参数:segmentShift，segmentMask 

Segment[] = 16(默认的并发级别)，则n = log16 = 4

segmentShift = 32-4 = 28  segmentMask = 2^n-1 = 15

Segment[hash >>>segmentShift & segmentMask]

 

![img](assets/wpsCxl1Mn.png) 

![img](assets/wpsfTCvIZ.png) 

get方法在多线程put和remove下线程安全的原因?

## **Synchronized**

synchronized可以修饰方法和代码块，这两种情况它们在字节码的表示层面是不一样的，

用javap反编译之后

可以看到对于同步方法它的标志符里面多了一个ACC_SYNCHRONIZED

如果设置了这个标志符，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。

而对于同步代码块来说，它通过monitorenter 和monitorexit这两条字节码指令来实现的，

线程执行monitorenter指令时尝试获取monitor的所有权，这又会有两种情况

如果monitor的计数为0 或者 当前线程是在这个monitor上重入，则线程可以直接进入，

否则线程就会阻塞在这里来等待这个计数重新为0。

## **volatile**

　　1.保证此变量对所有的线程的可见性，这里的“可见性”，如本文开头所述，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。

 

　　2.禁止指令重排序优化。有volatile修饰的变量，赋值后多执行了一个“lock addl $0x0, (%esp)”操作，这个操作相当于一个内存屏障（指令重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；（什么是指令重排序：是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理）。

 

 

 

 

当一个变量被定义成volatile之后，这个变量就具备了两层语义

1. 保证不同线程对这个变量操作时的可见性，

2. 保证有序性，禁止这个指令进行重排序，

 

可见性的含义是说当一个线程对变量进行修改之后，对其它线程来说，是可以立即感知的。

Java内存模型规定了，所有的变量都存储在主内存里面，同时每个线程都有自己的工作内存，

线程工作的时候会从主内存中拷贝一个副本，被volatile修饰的变量修改之后，会将这个值刷新到主内存中，同时会使这个变量的缓存无效，其它线程需要读取的时候，必须从主内存里面读。

 

有序性是通过CPU的Lock指令，这个指令有一个内存屏障的作用，保证之后的指令不会重排到这个lock指令之前。这里面对volatile变量还有一个先行发生原则，保证写操作是优先于写操作的，这样每次读取到的都是最新的值。

## **happens-before原则**

1.程序次序规则：

2.锁定原则：

3.volatile变量规则

4.传递规则

5.线程启动原则：

6.线程中断规则：

7.线程终结原则：

8.对象的终结规则：

 

## **Synchronized与Lock的区别**

1.首先synchronized是java内置关键字，在jvm层面，Lock是个java类 是API层面，；

 

2.synchronized无法判断是否获取锁的状态，以及不可中断的获取锁，Lock可以；

 

3.synchronized在退出同步区域时会自动释放锁，而Lock需在finally中手工释放锁，否则容易造成线程死锁；

4.synchronized是不公平的，Lock可以实现公平锁(因为它用到了AQS队列同步器)，读写锁。

 

## **谈谈你对线程池的理解**

**what**

“线程池”顾名思义，就是存放线程的池子，线程池是一种多线程处理形式，一种对线程的管理方法。

**why**

1. 复用已经存在的线程，减少了这个线程创建和销毁的这个开销

2. 提高了线程的可管理性，可以有效的控制最大并发线程数，避免了过多的资源竞争

3. 提供了定期执行、定时执行、单线程控制功能

**how：**

在用这个线程池处理多线程的形式下，任务是提交给整个线程池，而不是直接提交给某个线程，线程池在拿到任务后，会寻找是否有空闲的线程，如果有，则将任务交给某个空闲的线程。如果没有则将线程放进等待队列，这个队列指定是有界的还是无界的，无界的队列可以一直接收任务，而有界的队列在满了之后则会执行拒绝策略，默认是会抛一个异常。

 

## **execute和submit的区别：**

public interface Executor {

​    void execute(Runnable command);

}

 

public interface ExecutorService extends Executor {

​    <T> Future<T> submit(Callable<T> task);

​    <T> Future<T> submit(Runnable task, T result);

​    Future<?> submit(Runnable task);

}

 

 

## **抽象类和接口的区别**

抽象类是用来捕捉子类的通用特性的 。它不能被实例化，只能被用作子类的超类。抽象类是被用来创建继承层级里子类的模板。

 

而接口像是定义一个契约，接口中是抽象方法的集合。如果一个类实现了某个接口，那么就必须确保实现这些方法。 或者让一个类具备某种特性。比如说Serializable。实现这个接口的类就能被序列化。接口只是一种形式，接口自身不能做任何事情。

 

## **受检型异常和运行时异常**

受检型异常其必须被try...catch语句块所捕获,或者在方法签名里通过throws子句声明。

运行时异常, 需要程序员自己分析代码决定是否捕获和处理,比如空指针,被0除，以及对不些不合法参数的检查。

受检型异常代表:ReflectiveOperationException IOException

运行时异常代表:RuntimeException

# **框架**

## **SpringMVC的工作原理**

1、  用户发送请求至前端控制器DispatcherServlet。

 

2、  DispatcherServlet收到请求调用HandlerMapping处理器映射器。

 

3、  处理器映射器通过url找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。

 

4、  DispatcherServlet调用HandlerAdapter处理器适配器。

 

5、  HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。

 

6、  Controller执行完成返回ModelAndView。

 

7、  HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。

 

8、  DispatcherServlet将ModelAndView传给ViewReslover视图解析器。

 

9、  ViewReslover解析后返回具体View。

 

10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。

 

11、 DispatcherServlet响应用户。

 

 

## **对Spring IOC AOP的理解**

**IOC**

传统上由程序代码直接new对象，这样的缺点是耦合度太高。即便是在面向接口编程的场合，如果我想更改一个类的实现类。那我就需要改代码，并且所有用到这个类的地方都要改。

控制反转是把创建对象的权利交给Spring容器，通过IOC容器动态注入解耦合，如果要修改实现类只要改配置文件就可以了。

**AOP**

AOP它利用一种称为“横切”的技术，将那些跨横切面的逻辑抽取出来封装到一个可重用切面。

例如日志功能。日志代码往往水平地散布在所有对象层次中，而与它所散布到的对象的核心功能毫无关系。类以的还有，如权限检查、异常处理、事务管理也是类似的。

AOP的好处就是可以将那些与业务无关，却为业务模块所共同调用的逻辑封装起来，便于减少系统的重复代码以及做一个统一的管理。

## **Mybatis#和$的区别**

![img](assets/wpsH85Uvv.png) 

![img](assets/wpsjJbAXH.png) 

# 微服务
## 怎么理解微服务

## 服务拆分的原则


# **JVM**

## **垃圾收集算法**

复制算法，标记清除， 标记整理， 分代收集。

## **哪些对象可以作为GC Roots**

方法区中类静态属性引用的对象（static）

方法区中常量引用的对象（final）

虚拟机栈中引用的对象

本地方法栈中引用的对象

## **CMS收集器**

CMS(Concurrent Mark Sweep)收集器是一种获取最短回收停顿时间为目标的收集器，基于"标记-清除"算法实现，整个过程分为四步

**初始标记(CMS initial mark)->并发标记(CMS concurrent mark)->重新标记 (CMS remark)->并发清除 (CMS concurrent sweep)**

初始标记、重新标记着两个步骤任然需要"Stop The World"，{初始标记仅仅只是标记一下GCRoots能直接关联到的对象}，速度很快，{并发标记就是进行GC Roots Tracing 的过程}，而{重新标记阶段则是为了修正并发标记期间因用户程序继续运行而导致标记产品变动的那一部分对象的标记记录}。这个阶段的停顿时间一般会比初始标记阶段稍长一些。，但远比并发标记的时间短。

由于整个过程耗时最长的并发标记和并发清除都可以和用户线程一起工作，所以从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。CMS是一款优秀的收集器，它的主要优点在于：并发收集、低停顿。

CMS 收集器的缺点

-	**CMS收集器对CPU非常敏感**。其实面向并发设计的程序都对CPU比较敏感，在并发阶段，虽然不会导致用户线程停顿，但是会因为占用了一部分线程(或者说CPU资源)而导致应用程序变慢，总吞吐量降低。CMS默认启动的回收线程数是(CPU数量+3)/4,也就是当CPU在4个以上时，并发回收时，垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU数量不足4个时，CMS对用户程序的影响就可能变的很大。如果CPU负载本来就很大，还要分出一半的运行能力去执行收集器线程，就可能导致用户程序的执行能力下降50%

 

-	**CMS收集器无法处理浮动垃圾**。可能出现"Concurrent Mode Failure"失败而导致另一次Full GC。由于CMS并发清理阶段用户线程还在运行着，伴随着程序的运行自然就还会有新的垃圾不断产生，这一部分产生的垃圾，CMS无法在当次收集中处理掉他们，只要留待下一次GC再进行处理。这一部分产生的垃圾成为"浮动垃圾"。也是由于在垃圾收集阶段用户线程还要继续运行，那也就还需要预留足够的内存空间给用户线程使用。因此CMS收集器不能像其他收集器那样，等到老年代被填满后再进行垃圾回收。需要预留一部分空间供并发收集时的程序运行使用。

 

-	**由于CMS采用"标记清理"算法实现**，所以当垃圾收集后，会产生大量的内存碎片。空间碎片过多，当程序运行需要分配大对象时，由于找不到连续的内存空间，而不得不提前触发一次Full GC.CMS采用了-XX:+UseCMSCompactAtFullCollection开关参数，用于在CMS收集器顶不住要进行Full GC时开启内存碎片的合并整理过程。内存碎片的整理是无法并发执行的，空间碎片问题没有了，但是随之而来的停顿时间变长了。因此，虚拟机设计者还提供了一个参数：-XX:CMSFullGCsBeforeCompaction来进行设置执行多少次不压缩的Full GC后进行一次带压缩的(默认是0.标识每次进入Full GC后都会带有一次内存压缩)

 

 

 

# **数据库**

## **数据库并发控制**

### **事务的ACID特性**

**原子性**：事务中的操作序列要么全部执行，要么都不执行

**一致性**：事务的执行结果从一个一致性状态到另一个一致性状态(只包含成功提交的事务，是和原子性息息相关的) 比如说转帐的例子

**隔离性：**一个事务的执行不能被其他事务干扰

**持续性：**事务一但提交，对数据库的更改应该是永久性的

### **并发事务带来的问题**

 

在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对统一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。

 

•脏读（Dirty read）: 当一个事务对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务访问了这个还没有提交的数据。

 

•丢失修改（Lost to modify）: 两个事务t1,t2读入同一数据并修改并提交，最终只会保留最后一个事务的提交结果，导致其它事务提交的结果

丢失了 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。

 

•不可重复读（Unrepeatableread）: 不可重复读不指事务t1读取数据后，事务t2修改了数据，使t1无法再现前一次的读取结果

 

•幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

 

不可重复度和幻读区别：

 

不可重复读的重点是修改，幻读的重点在于新增或者删除。

 

例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导 致A再读自己的工资时工资变为 2000；这就是不可重复读。

 

例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。

 

 

 

### **事务的隔离级别**

SQL 标准定义了四个隔离级别：

 

•READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致**脏读、不可重复读或幻读**

•READ-COMMITTED(读取已提交): 允许读取并发事务已经提交的数据，可以阻止脏读，但是**不可重复读或幻读仍有可能发生**

•REPEATABLE-READ（可重读）: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但**幻读**仍有可能发生。

•SERIALIZABLE(可串行化): 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

 

MySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ**（可重读）。我们可以通过SELECT @@tx_isolation;命令来查看

## **in和exists的区别**

https://www.jianshu.com/p/f212527d76ff

![img](assets/wpsQ7dssk.jpg) 

![img](assets/wpsitzyzu.jpg) 

![img](assets/wpspJ9evg.jpg) 

in不走索引?

# **算法**

## **堆排序**

要说堆排序，我们先来说下堆这种数据结构，

堆是完全二叉树的一种：每个结点的值都大于或等于其左右孩子叫大顶堆；每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。

堆上的操作有建堆以及堆调整。

 

堆排序正是利用堆这种数据结构而设计的一种排序算法，以升序为例，堆排序的基本思想是：将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根节点。将其与末尾元素进行交换，此时末尾就为最大值。

然后将剩余n-1个元素堆调整，再次将堆顶元素和倒数第二个位置上的数进行交换，重复这个过程n-1次，便能得到一个升序的序列了。

 

整体主要由建堆，堆调整两部分组成。其中构建初始堆经推导复杂度为O(n)，在重建堆的过程中，要重复n-1次，每次是(lgn),

所以总的时间复杂度是O(nlgn)

 

## **快速排序**

 

快速排序是冒泡排序的改进版，也是最好的一种内排序，在很多面试题中都会出现，也是作为程序员必须掌握的一种排序方法。

 

思想:

1.在待排序的元素任取一个元素作为主元(通常选第一个元素，但最的选择方法是从待排序元素中随机选取一个作为基准)，称为基准元素；

 

2.将待排序的元素进行分区，比基准元素大的元素放在它的右边，比其小的放在它的左边；

 

3.对左右两个分区重复以上步骤直到所有元素都排好序。

 

